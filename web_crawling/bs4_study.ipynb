{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 크롤링, 웹 스크래핑\n",
    "# 크롤링 -> 전체를 다 가져오는 것\n",
    "# 스크래핑 -> 필요한 부분만 가져오는 것\n",
    "# 정적 크롤링, 동적 크롤링\n",
    "# 정적크롤링 -> beautifulsoup\n",
    "# 동적크롤링 -> beautifulsoup, selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세노비스 트리플러스 멀티비타민 미네랄 트윈 세트 + 쇼핑백, 100정, 2개\n",
      "풍년보감 6년근 고려홍삼정 올데이굿타임 골드 진세노사이드 15mg 홍삼스틱 100포, 1000g, 1개\n",
      "쿤달 퍼퓸 디퓨저 200ml 3개 + 섬유스틱 15개 세트, 베이비파우더향\n",
      "청정원 두번달여 더진한 진간장, 1.7L, 1개\n",
      "락앤락 비스프리 모듈러 밀폐용기 세트, 4개입, 단품\n",
      "닥터지 블랙 스네일 프레스티지 스킨케어 토너 150ml + 에멀전 150ml + 크림 50ml 세트, 1세트\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = \"https://pages.coupang.com/p/96636\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "html = bs(response.text)   #해당 response의 html을 다 들고온다.\n",
    "findInfo_sectionTitle = html.find_all(\"span\", class_=\"info_section__title\")   # find는 젤 위에있는 하나만 들고옴 (태그랑, 클래스명으로 가져옴)\n",
    "for title in findInfo_sectionTitle:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gzero/AWS/python/basic/web_crawling/bs4_study.ipynb 셀 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gzero/AWS/python/basic/web_crawling/bs4_study.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gzero/AWS/python/basic/web_crawling/bs4_study.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# 검색어 입력\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gzero/AWS/python/basic/web_crawling/bs4_study.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m search_keyword \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m어떤 공공데이터를 찾으시나요? \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gzero/AWS/python/basic/web_crawling/bs4_study.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# 페이지 범위 입력\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gzero/AWS/python/basic/web_crawling/bs4_study.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m page_range \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m수집하실 페이지 범위를 입력하세요 (예: 1~4): \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1172\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_request(\n\u001b[1;32m   1176\u001b[0m     \u001b[39mstr\u001b[39m(prompt),\n\u001b[1;32m   1177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_ident[\u001b[39m\"\u001b[39m\u001b[39mshell\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1178\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_parent(\u001b[39m\"\u001b[39m\u001b[39mshell\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1179\u001b[0m     password\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1180\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# 검색어 입력\n",
    "search_keyword = input(\"어떤 공공데이터를 찾으시나요? \")\n",
    "\n",
    "# 페이지 범위 입력\n",
    "page_range = input(\"수집하실 페이지 범위를 입력하세요 (예: 1~4): \")\n",
    "start_page, end_page = map(int, page_range.split('~'))\n",
    "\n",
    "# 검색 결과를 저장할 리스트\n",
    "data_info = []\n",
    "\n",
    "# 검색 결과 페이지 순회\n",
    "for page in range(start_page, end_page + 1):\n",
    "    # 검색 결과 페이지 URL 생성\n",
    "    url = f\"https://www.data.go.kr/index.do?keyword={search_keyword}&currentPage={page}\"\n",
    "\n",
    "    # 페이지 내용 가져오기\n",
    "    response = requests.get(url)\n",
    "    print(response)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    print(soup)\n",
    "    # 검색 결과 목록 추출\n",
    "    results = soup.find_all('div', class_='result')\n",
    "\n",
    "    # 검색 결과 순회\n",
    "    for result in results:\n",
    "        title = result.find('h2').text.strip()  # 도서 제목\n",
    "        description = result.find('div', class_='text').text.strip()  # 도서 설명\n",
    "        link = result.find('a', class_='tit')['href']  # 도서 링크\n",
    "\n",
    "        # 검색 결과를 딕셔너리로 저장\n",
    "        data_info.append({\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "            'link': link\n",
    "        })\n",
    "\n",
    "# 검색 결과를 출력\n",
    "for data in data_info:\n",
    "    print(f\"Title: {data['title']}\")\n",
    "    print(f\"Description: {data['description']}\")\n",
    "    print(f\"Link: {data['link']}\")\n",
    "    print()\n",
    "\n",
    "print(data_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
